{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport glob\nimport json\nimport re\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"**Goal**\n- With a large amount of literature and fast spreading of COVID-19. It's difficult for health care professionals figure out relevant research. \n- In this post, we will try to identify which topic is discussed in research. It also reduce number of articles which scientist has go through. \n- Research paper topic modelling is an unsupervised machine learning method which allow us to learn topic of articles in corpus"},{"metadata":{},"cell_type":"markdown","source":"*ok Lets go*\n- Because kaggle provided us lot of json file so we will load all json data to dataframe and drop abstract duplicate to make sure unique articles"},{"metadata":{"trusted":true},"cell_type":"code","source":"#path = '/kaggle/input/CORD-19-research-challenge/comm_use_subset/'\npath = '/kaggle/input/'\nall_json = glob.glob(f'{path}/**/*.json', recursive=True)\nclass FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.abstract = []\n            self.body_text = []\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\ndict_ = {'paper_id': [], 'abstract': [], 'body_text': []}\nfor idx, entry in enumerate(all_json):\n    if idx % (len(all_json) // 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json)}')\n    content = FileReader(entry)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['abstract'].append(content.abstract)\n    dict_['body_text'].append(content.body_text)\ncovid_df = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text'])\ncovid_df.drop_duplicates(['abstract'], inplace=True)\ncovid_df.head()","execution_count":6,"outputs":[{"output_type":"stream","text":"Processing index: 0 of 29315\nProcessing index: 2931 of 29315\nProcessing index: 5862 of 29315\nProcessing index: 8793 of 29315\nProcessing index: 11724 of 29315\nProcessing index: 14655 of 29315\nProcessing index: 17586 of 29315\nProcessing index: 20517 of 29315\nProcessing index: 23448 of 29315\nProcessing index: 26379 of 29315\nProcessing index: 29310 of 29315\n","name":"stdout"},{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"                                   paper_id  \\\n0  25621281691205eb015383cbac839182b838514f   \n1  7db22f7f81977109d493a0edf8ed75562648e839   \n2  a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a   \n3  6c3e1a43f0e199876d4bd9ff787e1911fd5cfaa6   \n4  2ce201c2ba233a562ee605a9aa12d2719cfa2beb   \n\n                                            abstract  \\\n0  The human interferon (IFN)-induced MxA protein...   \n1  Scorpine, a small cationic peptide from the ve...   \n2  Background: The complex interplay between vira...   \n3                                                      \n4  Background: Human adenovirus type 55 is a re-e...   \n\n                                           body_text  \n0  Influenza A viruses (IAV) are severe human pat...  \n1  The oldest known scorpions lived around 430 mi...  \n2  The emergence of Severe Acute Respiratory Synd...  \n3  Sjögren's syndrome (SS) is a connective tissue...  \n4  Human adenovirus (HAdV) is a common pathogen a...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>abstract</th>\n      <th>body_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25621281691205eb015383cbac839182b838514f</td>\n      <td>The human interferon (IFN)-induced MxA protein...</td>\n      <td>Influenza A viruses (IAV) are severe human pat...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7db22f7f81977109d493a0edf8ed75562648e839</td>\n      <td>Scorpine, a small cationic peptide from the ve...</td>\n      <td>The oldest known scorpions lived around 430 mi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a</td>\n      <td>Background: The complex interplay between vira...</td>\n      <td>The emergence of Severe Acute Respiratory Synd...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6c3e1a43f0e199876d4bd9ff787e1911fd5cfaa6</td>\n      <td></td>\n      <td>Sjögren's syndrome (SS) is a connective tissue...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2ce201c2ba233a562ee605a9aa12d2719cfa2beb</td>\n      <td>Background: Human adenovirus type 55 is a re-e...</td>\n      <td>Human adenovirus (HAdV) is a common pathogen a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We have to clean-up the text by \n- Remove punctuation\n- Convert each text to lower case"},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_df['body_text'] = covid_df['body_text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\ncovid_df['abstract'] = covid_df['abstract'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n\ndef lower_case(input_str):\n    input_str = input_str.lower()\n    return input_str\n\ncovid_df['body_text'] = covid_df['body_text'].apply(lambda x: lower_case(x))\ncovid_df['abstract'] = covid_df['abstract'].apply(lambda x: lower_case(x))\ncovid_df.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                                   paper_id  \\\n0  25621281691205eb015383cbac839182b838514f   \n1  7db22f7f81977109d493a0edf8ed75562648e839   \n2  a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a   \n3  6c3e1a43f0e199876d4bd9ff787e1911fd5cfaa6   \n4  2ce201c2ba233a562ee605a9aa12d2719cfa2beb   \n\n                                            abstract  \\\n0  the human interferon ifninduced mxa protein is...   \n1  scorpine a small cationic peptide from the ven...   \n2  background the complex interplay between viral...   \n3                                                      \n4  background human adenovirus type 55 is a reeme...   \n\n                                           body_text  \n0  influenza a viruses iav are severe human patho...  \n1  the oldest known scorpions lived around 430 mi...  \n2  the emergence of severe acute respiratory synd...  \n3  sjgrens syndrome ss is a connective tissue dis...  \n4  human adenovirus hadv is a common pathogen amo...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>abstract</th>\n      <th>body_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25621281691205eb015383cbac839182b838514f</td>\n      <td>the human interferon ifninduced mxa protein is...</td>\n      <td>influenza a viruses iav are severe human patho...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7db22f7f81977109d493a0edf8ed75562648e839</td>\n      <td>scorpine a small cationic peptide from the ven...</td>\n      <td>the oldest known scorpions lived around 430 mi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a</td>\n      <td>background the complex interplay between viral...</td>\n      <td>the emergence of severe acute respiratory synd...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6c3e1a43f0e199876d4bd9ff787e1911fd5cfaa6</td>\n      <td></td>\n      <td>sjgrens syndrome ss is a connective tissue dis...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2ce201c2ba233a562ee605a9aa12d2719cfa2beb</td>\n      <td>background human adenovirus type 55 is a reeme...</td>\n      <td>human adenovirus hadv is a common pathogen amo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- Because we only need body_text of the article so we will drop paper_id and abstract then save clean file, we will use it later"},{"metadata":{"trusted":true},"cell_type":"code","source":"text = covid_df.drop([\"paper_id\", \"abstract\"], axis=1)\ntext.head()\ntext.to_csv('./clean_text.csv')","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Next we will import spacy. If you never installed spacy before then you have to install before import\n- If you are using anaconda then implement\n    - *conda install -c conda-forge spacy*\n- If you are not using anaconda and you want to install via pip then implement:\n    - *pip install -U spacy*\n- If you want to install from source then implement:\n    - *git clone https://github.com/explosion/spaCy\n    - *cd spaCy*\n    - *pip install -r requirements.txt*\n    - *python setup.py build_ext - inplace*\n- You can refer to this page for more option: https://spacy.io/usage\n- **Then what is spaCy ?**\n    - spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n    - If you're working with a lot of text, you'll eventually want to know more about it. For example, what's it about? What do the words mean in context? Who is doing what to whom? What companies and products are mentioned? Which texts are similar to each other?\n    - spaCy is designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning ([source](https://spacy.io/usage/spacy-101))\n- ok let's import spacy"},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nspacy.load('en')\nfrom spacy.lang.en import English\nparser = English()","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will use following function to clean our text and return list of tokens:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(text):\n    lda_tokens = []\n    tokens = parser(text)\n    for token in tokens:\n        if token.orth_.isspace():\n            continue\n        elif token.like_url:\n            lda_tokens.append('URL')\n        elif token.orth_.startswith('@'):\n            lda_tokens.append('SCREEN_NAME')\n        else:\n            lda_tokens.append(token.lower_)\n    return lda_tokens","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use NLTK’s Wordnet to find the meanings of words, synonyms, antonyms, and more. In addition, we use WordNetLemmatizer to get the root word."},{"metadata":{},"cell_type":"markdown","source":"- We use NLTK Wordnet and WordNetLemmatizer to find the meaning of words such as synonyms, antonyms, etc. and also get the root word\n- Before that feel free to install nltk and download wordnet together with stopword\n    - *pip install - user -U nltk*\n    - *nltk.download('wordnet')*\n    - *nltk.download('stopwords')*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import wordnet as wn\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\ndef get_lemma(word):\n    lemma = wn.morphy(word)\n    if lemma is None:\n        return word\n    else:\n        return lemma\ndef get_lemma2(word):\n    return WordNetLemmatizer().lemmatize(word)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Filter out stop words:"},{"metadata":{"trusted":true},"cell_type":"code","source":"en_stop = set(nltk.corpus.stopwords.words('english'))","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can define a function to prepare the text for topic modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_text_for_lda(text):\n    tokens = tokenize(text)\n    tokens = [token for token in tokens if len(token) > 4]\n    tokens = [token for token in tokens if token not in en_stop]\n    tokens = [get_lemma(token) for token in tokens]\n    return tokens","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Open up our data, read line by line, for each line, prepare text for LDA, then add to a list.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_data = []\nwith open('./clean_text.csv') as f:\n    for line in f:\n        tokens = prepare_text_for_lda(line)\n        text_data.append(tokens)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Latent Dirichlet Allocation (LDA) with Gensim**\n- What is Gensim ?\n    - Gensim = \"Generate Similar\". \n    - Gensim started off as a collection of various Python scripts for the Czech Digital Mathematics Library dml.cz in 2008, where it served to generate a short list of the most similar articles to a given article (source)\n- Install Gensim via anaconda\n    - conda install -c anaconda gensim\n- Install Gensim via pip\n    - pip install - upgrade gensim\n    \n**Then what is LDA**\n- In natural language processing, the latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics. LDA is an example of a topic model and belongs to the machine learning toolbox and in wider sense to the artificial intelligence toolbox (source)\n- Ok, we will create a dictionary from the data, then convert to bag-of-words corpus and save the dictionary and corpus for future use"},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim import corpora\ndictionary = corpora.Dictionary(text_data)\ncorpus = [dictionary.doc2bow(text) for text in text_data]\nimport pickle\npickle.dump(corpus, open('corpus.pkl', 'wb'))\ndictionary.save('dictionary.gensim')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So we are trying to ask LDA to find 20 topics in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nNUM_TOPICS = 20\nldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\nldamodel.save('model20.gensim')\ntopics = ldamodel.print_topics(num_words=4)\nfor topic in topics:\n    print(topic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All topic related to virus mechanism but research on difference way"},{"metadata":{},"cell_type":"markdown","source":"# pyLDAvis\n- pyLDAvis is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization.\n- Visualizing 20 topics:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\ncorpus = pickle.load(open('corpus.pkl', 'rb'))\nlda = gensim.models.ldamodel.LdaModel.load('model20.gensim')\nimport pyLDAvis.gensim\nlda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\npyLDAvis.display(lda_display)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Saliency: a measure of how much the term tells you about the topic.\n- Relevance: a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n- The size of the bubble measures the importance of the topics, relative to the data.\n- First, we got the most salient terms, means terms mostly tell us about what’s going on relative to the topics. We can also look at individual topic."},{"metadata":{},"cell_type":"markdown","source":"When we have 20 or more topics, we can see certain topics are clustered together, this indicates the similarity between topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}